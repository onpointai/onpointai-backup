{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pytorch to Predict Pneumonia from X-Ray images\n",
    "> This notebook go through a complete data gathering, model development, training and prediction exercise using Deep Learning methods as contained in Pytorch.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [jovian, tensorflow, keras, pytorch, fastpages, jupyter]\n",
    "- image: images/tf-pytorch-1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This blog is towards the [Course Project](https://jovian.ml/forum/t/assignment-5-course-project/1563) for the [Pytorch Zero to GANS] free online course(https://jovian.ml/forum/c/pytorch-zero-to-gans/18) run by [JOVIAN.ML](https://www.jovian.ml).\n",
    "\n",
    "The course [competition](https://jovian.ml/forum/t/assignment-4-in-class-data-science-competition/1564/2) was based on analysing protein cells with muti-label classification.\n",
    "\n",
    "Therefore, to extend my understanding of dealing with medical imaging I decided to use the [X-Ray image database](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia) in Kaggle.\n",
    "\n",
    "Seeing as I ran out of GPU hours on Kaggle because of the competition (restricted to 30hrs/week at the time of writing June 2020) I opted to use Google Colab. \n",
    "\n",
    "This blog is in the form of a Jupyter notebook and inspired by [link](https://github.com/viritaromero/Detecting-Pneumonia-in-Chest-X-Rays/blob/master/Detecting_Pneumonia.ipynb).\n",
    "\n",
    "The blog talks about getting the dataset in Google Colab, explore the dataset, develop the training model, metrics and then does some preliminary training to get a model which is then used to make a few predictions. \n",
    "I will then talk about some of the lessons learned.\n",
    "\n",
    "> Warning! The purpose of this blog is to outline the steps taken in a typical Machine Learning project and should be treated as such."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1155,
     "status": "ok",
     "timestamp": 1592996787151,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "NXgIDphxMSLc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "import copy\n",
    "import PIL\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision.transforms as T\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from collections import OrderedDict\n",
    "from torchvision.utils import make_grid\n",
    "from torch.autograd import Variable\n",
    "import seaborn as sns\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab setup and getting data from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJ4GxXV7-yiC"
   },
   "source": [
    "I used Google Colab with GPU processing for this project because I had exhausted my Kaggle hours (30/wk). The challenge here was signing into Colab, setting up the working directoty and then linking to Kaggle and copying the data over. The sie of the dataset was about 1.3Gb.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20518,
     "status": "ok",
     "timestamp": 1592991761241,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "hKw4rH7m-yiE",
    "outputId": "4bf9fa44-0847-4f2c-dab4-f69f1fd2d807"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default directory that is linked to the Google's gdrive ( the one connected to the gmail address) is\n",
    "/content/drive/My Drive/\n",
    "\n",
    "I create a project directory jovian-xray and use this as the new root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 875,
     "status": "ok",
     "timestamp": 1592988101277,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "ksV82etl9lMC",
    "outputId": "e4b57186-b639-46f8-be63-599d092548ab"
   },
   "outputs": [],
   "source": [
    "os.listdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2892,
     "status": "ok",
     "timestamp": 1592991771798,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "MsWWRBYI9RT3",
    "outputId": "1e8823ea-80da-4f53-9bb0-b8f4a7835be4"
   },
   "outputs": [],
   "source": [
    "root_dir = '/content/drive/My Drive/jovian-xray'\n",
    "os.chdir(root_dir)\n",
    "!pwd\n",
    "os.mkdir('kaggle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Kaggle on Colab\n",
    "Log into Kaggle, point to the dataset and copy the API key. This downloads a kaggle.json file.\n",
    "Upload this kaggle.json to Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVU-NN697OPd"
   },
   "outputs": [],
   "source": [
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RX7Rwtj_7P7d"
   },
   "outputs": [],
   "source": [
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11334,
     "status": "ok",
     "timestamp": 1592912181517,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "EbJE-0ip7PyK",
    "outputId": "1fba594c-a589-4f0f-dc8a-dea17fc362ec"
   },
   "outputs": [],
   "source": [
    "upload = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2553,
     "status": "ok",
     "timestamp": 1592912300507,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "EQgK0GsZ80KT",
    "outputId": "d2fc08b3-430b-463e-e5eb-2b7fab55e6b5"
   },
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4670,
     "status": "ok",
     "timestamp": 1592912323970,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "JhejeoAt-0jo",
    "outputId": "def44925-ea6c-4a93-eafc-f3ffe4690096"
   },
   "outputs": [],
   "source": [
    "!ls\n",
    "! cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "utJPar1h-Sxy"
   },
   "outputs": [],
   "source": [
    " ! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2693,
     "status": "ok",
     "timestamp": 1592991779838,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "Q5RRbcsd_Njj",
    "outputId": "1524b689-f0fb-45a9-c7a7-7a4682b7c3ba"
   },
   "outputs": [],
   "source": [
    "proj_dir = os.path.join(root_dir, 'kaggle', 'chest_xray')\n",
    "os.chdir(proj_dir)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33672,
     "status": "ok",
     "timestamp": 1592912657341,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "cvGIyTKW_G4k",
    "outputId": "04da74a7-af18-49ae-9ac9-e231ea1bebc4"
   },
   "outputs": [],
   "source": [
    "#API key\n",
    "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2qvVoFVC_rlQ"
   },
   "outputs": [],
   "source": [
    "!unzip chest-xray-pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 982,
     "status": "ok",
     "timestamp": 1592921954662,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "1mDu3HYJ_rg6",
    "outputId": "a4635458-b29f-4828-f730-1bd7e3937e31"
   },
   "outputs": [],
   "source": [
    "os.listdir(proj_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is structured into training, val and test folders, each with sub-folders of NORMAL and PNEUMONIA images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image transforms\n",
    "\n",
    "We will now prepare the data for reading into Pytorch as numpy arrays using DataLoaders.\n",
    "\n",
    "Havig data augmentation is a good way to get extra training data for free. However, care must be taken to ensure that the transforms requested are likely to appear in the inference (or test set).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 995,
     "status": "ok",
     "timestamp": 1592992969806,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "8edp-RxrFUAE"
   },
   "outputs": [],
   "source": [
    "data_transforms = {'train' : T.Compose([\n",
    "    T.Resize(224),\n",
    "    T.CenterCrop(224),\n",
    "    T.RandomRotation(20),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "]),\n",
    "'test' : T.Compose([\n",
    "    T.Resize(224),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "]),\n",
    "'val' : T.Compose([\n",
    "    T.Resize(224),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 913,
     "status": "ok",
     "timestamp": 1592991785343,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "W5aK5zm-Q6lK",
    "outputId": "1bfbb373-91da-4844-f95c-00b31da278dd"
   },
   "outputs": [],
   "source": [
    "proj_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1285,
     "status": "ok",
     "timestamp": 1592996722840,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "yFd3MmZFw5Ac"
   },
   "outputs": [],
   "source": [
    "image_datasets = {x: datasets.ImageFolder(os.path.join(proj_dir, x),\n",
    "                                          data_transforms[x]) for x in ['train', 'val','test']}\n",
    "\n",
    "# Using the image datasets and the transforms, define the dataloaders\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=2) for x in ['train', 'val','test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "\n",
    "class_names= image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 972,
     "status": "ok",
     "timestamp": 1592993422011,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "VSR1m-88zNgi",
    "outputId": "3b2ddd43-18e4-458f-9ad6-75abdeff16ae"
   },
   "outputs": [],
   "source": [
    "print(image_datasets['train'][0][0].shape)\n",
    "print(image_datasets['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6030,
     "status": "ok",
     "timestamp": 1592993112648,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "wzhJDOmXyah2",
    "outputId": "94989250-21c1-48b1-92e9-b8a26baece85"
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "plt.figure(figsize=(8, 8))\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MaLbpoy4DX9A"
   },
   "source": [
    "## Use a Resnet152 model with our own classifier\n",
    "The Resnet152 model has a final fully connected layer to predict 1000 classes. In our case we need only two so we will remove the last fc layer and add our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "be171307fcc34e148e89819217a4d421",
      "22ac3b599ee447b79775fff9cbd343b9",
      "8df1fbc272d8452fab11f3847e046458",
      "0a3a7e4ae40c4b4fae745c03953348d0",
      "10f580b1ed08477487aaf0e8d7184b2d",
      "720c7b02581c4a969a7b7bdef57a1c0e",
      "bad4d3faa74549809bc9192525a19854",
      "03f8cbf801e04e85b287ff06692ce3eb"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3702,
     "status": "ok",
     "timestamp": 1592993462565,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "4ejK_LQFEnBq",
    "outputId": "66317949-10b6-4dcd-b1ff-4bb11b48a610"
   },
   "outputs": [],
   "source": [
    "# Build and train your network\n",
    "# 1. Load resnet-152 pre-trained network\n",
    "model = models.resnet152(pretrained=True)\n",
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Network architectur\n",
    "2. Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout\n",
    "\n",
    "The input_size matches the out_features of the pretrained model ie 1024.\n",
    "Out final output is two for the two classes ie NORMAL, PNEUMONIA.\n",
    "\n",
    "Use a LogSoftmax final activation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 990,
     "status": "ok",
     "timestamp": 1592993464612,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "5R312ah2Em-O"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(2048, 1024)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(1024, 2)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "\n",
    "# Replacing the pretrained model classifier with our classifier\n",
    "model.fc = classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the Training (and Validation) model\n",
    "\n",
    "The dataset has training, val and tests which makes our lives a little bot easier ie we don't have to do any data splitting and can set up specific transforms for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1626,
     "status": "ok",
     "timestamp": 1592995356478,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "OA89R06lEm59"
   },
   "outputs": [],
   "source": [
    "#Training the model\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best valid accuracy: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1326,
     "status": "ok",
     "timestamp": 1592995360242,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "OFNkvohnu0T_",
    "outputId": "7a33ce95-d11e-4190-cffe-546ed6a2284a"
   },
   "outputs": [],
   "source": [
    "nThreads = 4\n",
    "batch_size = 32\n",
    "use_gpu = torch.cuda.is_available()\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Training (and Validation) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1315,
     "status": "ok",
     "timestamp": 1592995364173,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "id2UbJoIupUc",
    "outputId": "b8d6493b-ecf9-4d38-cbc4-543a67a636db"
   },
   "outputs": [],
   "source": [
    "#Train a model with a pre-trained network\n",
    "num_epochs = 10\n",
    "if use_gpu:\n",
    "    print (\"Using GPU: \"+ str(use_gpu))\n",
    "    model = model.cuda()\n",
    "\n",
    "# NLLLoss because our output is LogSoftmax\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "#Adam optimizer with a learning rate\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.0001)\n",
    "#optimizer = optim.SGD(model.fc.parameters(), lr = .1, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 5 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1001724,
     "status": "ok",
     "timestamp": 1592996378589,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "wrIfuLHeupRZ",
    "outputId": "51ca64bf-c334-4bd8-d0a6-231f08fa2a6a"
   },
   "outputs": [],
   "source": [
    "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing (Inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1106,
     "status": "ok",
     "timestamp": 1592996660313,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "U1Tmwya-upLr"
   },
   "outputs": [],
   "source": [
    "# Do validation on the test set\n",
    "def test(model, dataloaders, device):\n",
    "  model.eval()\n",
    "  accuracy = 0\n",
    "  \n",
    "  model.to(device)\n",
    "    \n",
    "  for images, labels in dataloaders['test']:\n",
    "    images = Variable(images)\n",
    "    labels = Variable(labels)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "      \n",
    "    output = model.forward(images)\n",
    "    ps = torch.exp(output)\n",
    "    equality = (labels.data == ps.max(1)[1])\n",
    "    accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "      \n",
    "    print(\"Testing Accuracy: {:.3f}\".format(accuracy/len(dataloaders['test'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 151824,
     "status": "ok",
     "timestamp": 1592996943838,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "H0EfMYmwupIz",
    "outputId": "a08bb145-0038-496c-9f35-f2054ac8882a"
   },
   "outputs": [],
   "source": [
    "test(model, dataloaders, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the interim model (checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1687,
     "status": "ok",
     "timestamp": 1592997063638,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "2WlyYUa7BO52"
   },
   "outputs": [],
   "source": [
    "# Save the checkpoint \n",
    "model.class_to_idx = dataloaders['train'].dataset.class_to_idx\n",
    "model.epochs = num_epochs\n",
    "checkpoint = {'input_size': [2, 224, 224],\n",
    "                 'batch_size': dataloaders['train'].batch_size,\n",
    "                  'output_size':2,\n",
    "                  'state_dict': model.state_dict(),\n",
    "                  'data_transforms': data_transforms,\n",
    "                  'optimizer_dict':optimizer.state_dict(),\n",
    "                  'class_to_idx': model.class_to_idx,\n",
    "                  'epoch': model.epochs}\n",
    "save_fname= os.path.join(proj_dir, '90_checkpoint.pth')\n",
    "torch.save(checkpoint,  save_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that loads a checkpoint and rebuilds the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2601,
     "status": "ok",
     "timestamp": 1592997078805,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "bB7oNHpnupGC"
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = models.resnet152()\n",
    "    \n",
    "    # our input_size matches the in_features of pretrained model\n",
    "    input_size = 2048\n",
    "    output_size = 2\n",
    "    \n",
    "    classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(2048, 1024)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          #('dropout1', nn.Dropout(p=0.2)),\n",
    "                          ('fc2', nn.Linear(1024, 2)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "\n",
    "\n",
    "    # Replacing the pretrained model classifier with our classifier\n",
    "    model.fc = classifier\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model, checkpoint['class_to_idx']\n",
    "\n",
    "# Get index to class mapping\n",
    "loaded_model, class_to_idx = load_checkpoint(save_fname)\n",
    "idx_to_class = { v : k for k,v in class_to_idx.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the Training/Validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 972,
     "status": "ok",
     "timestamp": 1592997088113,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "P2iOP-0HupCr"
   },
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1638,
     "status": "ok",
     "timestamp": 1592997098344,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "z2tC6K0huo-O",
    "outputId": "5a47a5f4-afa6-4ac6-8246-4e31cdf3941a"
   },
   "outputs": [],
   "source": [
    "visualize_model(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 954,
     "status": "ok",
     "timestamp": 1592997498642,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "bUgschSeCB1A"
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    \n",
    "    # Process a PIL image for use in a PyTorch model\n",
    "    #T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    \n",
    "    size = 256, 256\n",
    "    image.thumbnail(size, Image.ANTIALIAS)\n",
    "    image = image.crop((128 - 112, 128 - 112, 128 + 112, 128 + 112))\n",
    "    npImage = np.array(image)\n",
    "    npImage = npImage/255.\n",
    "        \n",
    "    imgA = npImage[:,:,0]\n",
    "    imgB = npImage[:,:,1]\n",
    "    imgC = npImage[:,:,2]\n",
    "    \n",
    "    imgA = (imgA - 0.485)/(0.229) \n",
    "    imgB = (imgB - 0.456)/(0.224)\n",
    "    imgC = (imgC - 0.406)/(0.225)\n",
    "        \n",
    "    npImage[:,:,0] = imgA\n",
    "    npImage[:,:,1] = imgB\n",
    "    npImage[:,:,2] = imgC\n",
    "    \n",
    "    npImage = np.transpose(npImage, (2,0,1))\n",
    "    \n",
    "    return npImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 888,
     "status": "ok",
     "timestamp": 1592997513905,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "m5L-zLn1CByM"
   },
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((0, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "ok",
     "timestamp": 1592997230640,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "HMsrMVcUCBs5"
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "\n",
    "def predict(image_path, model, topk=2):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    \n",
    "    # Implement the code to predict the class from an image file\n",
    "    \n",
    "    image = torch.FloatTensor([process_image(Image.open(image_path).convert('RGB'))])\n",
    "    model.eval()\n",
    "    output = model.forward(Variable(image))\n",
    "    probabilities = torch.exp(output).data.numpy()[0]\n",
    "    \n",
    "\n",
    "    top_idx = np.argsort(probabilities)[-topk:][::-1] \n",
    "    top_class = [idx_to_class[x] for x in top_idx]\n",
    "    top_probability = probabilities[top_idx]\n",
    "\n",
    "    return top_probability, top_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1610,
     "status": "ok",
     "timestamp": 1592997705867,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "upiD5EbyCBqL",
    "outputId": "1eac216b-9c5f-4915-8628-2510ba8afb55"
   },
   "outputs": [],
   "source": [
    "print (predict('chest_xray/test/NORMAL/NORMAL2-IM-0348-0001.jpeg', loaded_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 883,
     "status": "ok",
     "timestamp": 1592997714051,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "ZuS7n3PZCBnB"
   },
   "outputs": [],
   "source": [
    "# Display an image along with the top  classes\n",
    "def view_classify(img, probabilities, classes, mapper):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    img_filename = 'Prediction'\n",
    "    img = Image.open(img)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,10),  ncols=1, nrows=2)\n",
    "    ct_name = img_filename\n",
    "    \n",
    "    ax1.set_title(ct_name)\n",
    "    ax1.imshow(img)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    y_pos = np.arange(len(probabilities))\n",
    "    ax2.barh(y_pos, probabilities, color='blue')\n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels(x for x in classes)\n",
    "    ax2.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1785,
     "status": "ok",
     "timestamp": 1592997717064,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "bRCPzE2cCBj8",
    "outputId": "4930e05e-4682-421d-edb7-6e77b1878cbf"
   },
   "outputs": [],
   "source": [
    "img = os.path.join(proj_dir, 'test/NORMAL/NORMAL2-IM-0347-0001.jpeg')\n",
    "p, c = predict(img, loaded_model)\n",
    "view_classify(img, p, c, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1508,
     "status": "ok",
     "timestamp": 1592997835834,
     "user": {
      "displayName": "Dexter D'Silva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhW_MLYF6gRb-aYgCSu3HZ63AR8fiI4Z9lPWaPL=s64",
      "userId": "14942342950933263184"
     },
     "user_tz": -60
    },
    "id": "5FomP4g4CiI0",
    "outputId": "3f3166b8-183e-4480-9e20-ecdd8c5744ef"
   },
   "outputs": [],
   "source": [
    "img = os.path.join(proj_dir, 'test/PNEUMONIA/person85_bacteria_421.jpeg')\n",
    "p, c = predict(img, loaded_model)\n",
    "view_classify(img, p, c, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lessons Learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are five methods to reduce model overfitting.  Overfitting results when the model fits very well to the training data (low error) but not very well to the validation data (high error).\n",
    "These are:\n",
    "> Get more data  \n",
    "> Data augmentation  \n",
    "> Generalizable architectures  \n",
    "> Regularisation  \n",
    "> Reduce architecture complexity  \n",
    "\n",
    "Using the Resnet152 arch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "jovian-xray-mthd-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03f8cbf801e04e85b287ff06692ce3eb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a3a7e4ae40c4b4fae745c03953348d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03f8cbf801e04e85b287ff06692ce3eb",
      "placeholder": "",
      "style": "IPY_MODEL_bad4d3faa74549809bc9192525a19854",
      "value": " 230M/230M [00:01&lt;00:00, 154MB/s]"
     }
    },
    "10f580b1ed08477487aaf0e8d7184b2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "22ac3b599ee447b79775fff9cbd343b9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "720c7b02581c4a969a7b7bdef57a1c0e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8df1fbc272d8452fab11f3847e046458": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_720c7b02581c4a969a7b7bdef57a1c0e",
      "max": 241530880,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10f580b1ed08477487aaf0e8d7184b2d",
      "value": 241530880
     }
    },
    "bad4d3faa74549809bc9192525a19854": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be171307fcc34e148e89819217a4d421": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8df1fbc272d8452fab11f3847e046458",
       "IPY_MODEL_0a3a7e4ae40c4b4fae745c03953348d0"
      ],
      "layout": "IPY_MODEL_22ac3b599ee447b79775fff9cbd343b9"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
