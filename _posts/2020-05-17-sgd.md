---
toc: true
layout: post
description: Demonstrate SGD -  the essence of Machine Learning
categories: [AI/ML Gradient Descent]
image: images/sgd.png
title: Stochastic Gradient Descent 
---

## Overview  

ML is basically this - you make a prediction, see how far that prediction is from the truth, fine-tune your prediction and keep going until the difference between between the prediction and the actual reaches an acceptable level. 
If we imagine the loss function plotted as a U curve then we are trying to reach the bottom of the curve as quickly as possible ie minimise the loss. From our starting point, a guess, we then take a small step in the direction of lower loss.
The small step is known as the learning rate and the direction of lower loss is worked out from the slope of the curve.

## Minimising the loss  

Below is a regression example. The pink dots are the initial set of data. To this we have to find a general approximation that will satisfy any new points.\
Our initial guess is the black line.\
![]({{"/"|relative_url}}/images/sgd-1.png "START")

We then go through the fllowing sequence:
Loss = New Value - Actual Value
Find slope of the loss function
Move down the loss curve by a small amount (the Learning Rate)
Find the new loss

[![](http://img.youtube.com/vi/rLf_0gN3NFo/0.jpg)](http://www.youtube.com/watch?v=rLf_0gN3NFo "MINIMISING THE LOSS")

> Pytorch implementation

```
y is the actual
y_hat is the prediction (based on a set of weights a)
loss is the mean squared error between y_hat and y


def mse(y_hat,y):
    return((y_hat-y)**2).mean()

def update():
    y_hat = x@a
    loss=mse(y_hat,y)
    loss.backward()
    with torch.no_grad():
        a.sub_(lr * a.grad)
        a.grad.zero_()
```
## References  

1. [Fast.ai](https://course.fast.ai/videos/?lesson=2)
2. [Machine Learning Mastery](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/)


[D]("https://github.githubassets.com/images/icons/emoji/bowtie.png?v8")
:bowtie:
---
![]({{"/"|relative_url}}/images/onpointai_logo.gif)
