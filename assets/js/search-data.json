{
  
    
        "post0": {
            "title": "Tensorflow & Pytorch comparison with CIFAR10",
            "content": "About . The third assigment of the course Pytorch Zero to GANS run by JOVIAN.ML is to go through a simple classification problem using the CIFAR10 dataset. The course uses Pytorch and as an option course attendees were asked to use Tensorflow to repeat the task. . The training was done on Google Colab with GPU. The good thing with running on Colab (and Binder, Kaggle to name a few others) is there is not much setup involved. Import the required libraries and off you go! . The Tensorflow version will be done first followed by the Pytorch version. The course assignment was in Pytorch (as the course title suggests) so the TF example was made to match that setup. . Colab setup . You will have to use your own API credentials. . from google.colab import drive drive.mount(&#39;/content/drive&#39;, force_remount=True) import os root_dir = &#39;/content/drive/My Drive/Colab Notebooks/jovian/&#39; . Mounted at /content/drive . Tensorflow/Keras . Import libraries . from __future__ import print_function import tensorflow as tf import keras from keras.datasets import cifar10 from keras.preprocessing.image import ImageDataGenerator from keras.models import Sequential from keras.layers import Dense, Dropout, Activation, Flatten from keras.utils import to_categorical import os import numpy as np from sklearn.model_selection import train_test_split import matplotlib.pyplot as plt %matplotlib inline . Data augmentation not used because this was not used in the Pytorch example below. ** . batch_size=128 epochs=20 data_augmentation=False . (X,y), (x_test,y_test) = cifar10.load_data() . Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz 170500096/170498071 [==============================] - 4s 0us/step . Explore the CIFAR10 dataset . # collapse-hide print(X.shape) print(y.shape) print(x_test.shape) print(y_test.shape) . . (50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1) . y_squeeze = np.squeeze(y) . # Create a classes list classes = [&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;] . #unique classes unique_classes = np.unique(y) num_classes = len(unique_classes) unique_classes . array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8) . unique, count = np.unique(y, return_counts=True) . for i in range(len(unique)): print(f&#39; class {classes[i] } has {count[i].item()} images&#39;) . class airplane has 5000 images class automobile has 5000 images class bird has 5000 images class cat has 5000 images class deer has 5000 images class dog has 5000 images class frog has 5000 images class horse has 5000 images class ship has 5000 images class truck has 5000 images . #collapse-hide fig = plt.figure(figsize=(6,6)) for i in range(9): plt.subplot(3,3,i+1) plt.imshow(X[i]) plt.show() . . Prepare the data for training . The Pytorch assignment used a 10% split of the training set for the validation set done using the randome_split Pytorch utility. So I will use scikitlearn&#39;s train_test_split to do the same the same on the training set. . x_train, x_val, y_train, y_val= train_test_split(X, y, test_size=0.1, random_state=42) . x_train=x_train.astype(&#39;float32&#39;)/255. x_val=x_val.astype(&#39;float32&#39;)/255. . y_train = to_categorical(y_train, num_classes) y_val = to_categorical(y_val, num_classes) print(x_train.shape) print(y_train.shape) . (45000, 32, 32, 3) (45000, 10) . y_train = np.squeeze(y_train) y_val=np.squeeze(y_val) . Set up a simple Keras model . model = Sequential() model.add(Flatten(input_shape=(32,32,3))) model.add(Dense(32,activation = &#39;relu&#39;)) model.add(Dense(num_classes)) model.add(Activation(&#39;softmax&#39;)) . model.summary() . Model: &#34;sequential_1&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= flatten_1 (Flatten) (None, 3072) 0 _________________________________________________________________ dense_1 (Dense) (None, 32) 98336 _________________________________________________________________ dense_2 (Dense) (None, 10) 330 _________________________________________________________________ activation_1 (Activation) (None, 10) 0 ================================================================= Total params: 98,666 Trainable params: 98,666 Non-trainable params: 0 _________________________________________________________________ . The number of model parameters must match that of Pytorch. . opt = keras.optimizers.SGD(learning_rate=1e-3) . model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=opt, metrics = [&#39;accuracy&#39;]) . H = model.fit(x_train, y_train, batch_size=batch_size, epochs = 20, validation_data=(x_val,y_val)) . print(H.history.keys()) . dict_keys([&#39;val_loss&#39;, &#39;val_accuracy&#39;, &#39;loss&#39;, &#39;accuracy&#39;]) . plt.title(&quot;ACCURACY&quot;) plt.plot(H.history[&#39;accuracy&#39;], label=&#39;train_acc&#39;) plt.plot(H.history[&#39;val_accuracy&#39;], label = &#39;val_acc&#39;) plt.legend() plt.show() . Evaluate the model on Test data . x_test =x_test.astype(&#39;float32&#39;)/255. y_test = to_categorical(y_test, num_classes) . y_test.shape . (10000, 10) . model.evaluate(x_test, y_test) . 10000/10000 [==============================] - 1s 94us/step . [1.8181508338928223, 0.3619999885559082] . . Pytorch . This is Assignment 03 modified for blogging purposes. . Import libraries . import torch import torchvision import numpy as np import matplotlib.pyplot as plt import torch.nn as nn import torch.nn.functional as F from torchvision.datasets import CIFAR10 from torchvision.transforms import ToTensor from torchvision.utils import make_grid from torch.utils.data.dataloader import DataLoader from torch.utils.data import random_split %matplotlib inline . # Project name used for jovian.commit project_name = &#39;03-cifar10-feedforward&#39; . proj_dir = os.path.join(root_dir, project_name) proj_dir . &#39;/content/drive/My Drive/Colab Notebooks/jovian/03-cifar10-feedforward&#39; . Exploring the CIFAR10 dataset . dataset = CIFAR10(root=proj_dir, download=True, transform=ToTensor()) test_dataset = CIFAR10(root=proj_dir, train=False, transform=ToTensor()) . Files already downloaded and verified . dataset_size = len(dataset) dataset_size . 50000 . test_dataset_size = len(test_dataset) test_dataset_size . 10000 . classes = dataset.classes classes . [&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;] . num_classes = len(dataset.classes) num_classes . 10 . Note that this dataset consists of 3-channel color images (RGB). Let us look at a sample image from the dataset. matplotlib expects channels to be the last dimension of the image tensors (whereas in PyTorch they are the first dimension), so we&#39;ll the .permute tensor method to shift channels to the last dimension. Let&#39;s also print the label for the image. . The number of images belonging to each class . Credit . #get the label of the dataset using the [1] index img, label = dataset[1] label_of_image_1 = dataset[1][1] title= str(label_of_image_1) + &#39; is a &#39; + classes[label_of_image_1] plt.imshow(img.permute(1,2,0)) plt.title(title) plt.show() . label_of_train_images=[] for i in range(len(dataset)): label_of_train_image = dataset[i][1] label_of_train_images.append(label_of_train_image) . num_unique_train_labels = np.unique(label_of_train_images) . uniq_image_count = torch.stack([(torch.tensor(label_of_train_images)==i).sum() for i in num_unique_train_labels]) . for i in range(len(uniq_image_count)): print(f&#39; class {classes[i] } has {uniq_image_count[i].item()} images&#39;) . class airplane has 5000 images class automobile has 5000 images class bird has 5000 images class cat has 5000 images class deer has 5000 images class dog has 5000 images class frog has 5000 images class horse has 5000 images class ship has 5000 images class truck has 5000 images . Prepare the data for training . torch.manual_seed(43) val_size = 5000 train_size = len(dataset) - val_size . Let&#39;s use the random_split method to create the training &amp; validation sets . train_ds, val_ds = random_split(dataset, [train_size, val_size]) len(train_ds), len(val_ds) . (45000, 5000) . We can now create data loaders to load the data in batches. . batch_size=128 . train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True) val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True) test_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True) . Let&#39;s visualize a batch of data using the make_grid helper function from Torchvision. . #collapse-hide viz_loader = DataLoader(train_ds, 9, shuffle=True, num_workers=4, pin_memory=True) for images, _ in viz_loader: plt.figure(figsize=(6,6)) plt.axis(&#39;off&#39;) plt.imshow(make_grid(images, nrow=3).permute((1, 2, 0))) break . . Base Model class &amp; Training on GPU . Let&#39;s create a base model class, which contains everything except the model architecture i.e. it wil not contain the __init__ and __forward__ methods. We will later extend this class to try out different architectures. In fact, you can extend this model to solve any image classification problem. . def accuracy(outputs, labels): _, preds = torch.max(outputs, dim =1) return torch.tensor(torch.sum(preds== labels).item()/len(preds)) . class ImageClassificationBase(nn.Module): def training_step(self, batch): images, labels = batch out = self(images) # Generate predictions loss = F.cross_entropy(out, labels) # Calculate loss return loss def validation_step(self, batch): images, labels = batch out = self(images) # Generate predictions loss = F.cross_entropy(out, labels) # Calculate loss #change from cross_entropy acc = accuracy(out, labels) # Calculate accuracy return {&#39;val_loss&#39;: loss, &#39;val_acc&#39;: acc} def validation_epoch_end(self, outputs): batch_losses = [x[&#39;val_loss&#39;] for x in outputs] epoch_loss = torch.stack(batch_losses).mean() # Combine losses batch_accs = [x[&#39;val_acc&#39;] for x in outputs] epoch_acc = torch.stack(batch_accs).mean() # Combine accuracies return {&#39;val_loss&#39;: epoch_loss.item(), &#39;val_acc&#39;: epoch_acc.item()} def epoch_end(self, epoch, result): print(&quot;Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}&quot;.format(epoch, result[&#39;val_loss&#39;], result[&#39;val_acc&#39;])) . We can also use the exact same training loop as before. I hope you&#39;re starting to see the benefits of refactoring our code into reusable functions. . def evaluate(model, val_loader): outputs = [model.validation_step(batch) for batch in val_loader] return model.validation_epoch_end(outputs) def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD): history = [] optimizer = opt_func(model.parameters(), lr) for epoch in range(epochs): # Training Phase for batch in train_loader: loss = model.training_step(batch) loss.backward() optimizer.step() optimizer.zero_grad() # Validation phase result = evaluate(model, val_loader) model.epoch_end(epoch, result) history.append(result) return history . Finally, let&#39;s also define some utilities for moving out data &amp; labels to the GPU, if one is available. . Let us also define a couple of helper functions for plotting the losses &amp; accuracies. . def plot_losses(history): losses = [x[&#39;val_loss&#39;] for x in history] plt.plot(losses, &#39;-x&#39;) plt.xlabel(&#39;epoch&#39;) plt.ylabel(&#39;loss&#39;) plt.title(&#39;Loss vs. No. of epochs&#39;); . def plot_accuracies(history): accuracies = [x[&#39;val_acc&#39;] for x in history] plt.plot(accuracies, &#39;-o&#39;) plt.xlabel(&#39;epoch&#39;) plt.ylabel(&#39;accuracy&#39;) plt.title(&#39;Pytorch Accuracy vs. No. of epochs&#39;); . Let&#39;s move our data loaders to the appropriate device. . input_size = 3*32*32 hidden_size = 32 output_size = 10 . class CIFAR10Model(ImageClassificationBase): def __init__(self): super().__init__() #dd hidden layer self.linear1 = nn.Linear(input_size, hidden_size) #output layer self.linear2 = nn.Linear(hidden_size, output_size) def forward(self, xb): # Flatten images into vectors out = xb.view(xb.size(0), -1) # Apply layers &amp; activation functions out = self.linear1(out) out = F.relu(out) out = self.linear2(out) return out . You can now instantiate the model, and move it the appropriate device. . #USING A GPU torch.cuda.is_available() def get_default_device(): &quot;&quot;&quot;Pick GPU if available, else CPU&quot;&quot;&quot; if torch.cuda.is_available(): return torch.device(&#39;cuda&#39;) else: return torch.device(&#39;cpu&#39;) device = get_default_device() print(device) def to_device(data, device): &quot;&quot;&quot;Move tensor(s) to chosen device&quot;&quot;&quot; if isinstance(data, (list,tuple)): return [to_device(x, device) for x in data] return data.to(device, non_blocking=True) for images, labels in train_loader: print(images.shape) images = to_device(images, device) print(images.device) break . cuda torch.Size([128, 3, 32, 32]) cuda:0 . model = to_device(CIFAR10Model(), device) . print(model.parameters) for t in model.parameters(): print(t.shape) . &lt;bound method Module.parameters of CIFAR10Model( (linear1): Linear(in_features=3072, out_features=32, bias=True) (linear2): Linear(in_features=32, out_features=10, bias=True) )&gt; torch.Size([32, 3072]) torch.Size([32]) torch.Size([10, 32]) torch.Size([10]) . Before you train the model, it&#39;s a good idea to check the validation loss &amp; accuracy with the initial set of weights. . #collapse-hide pytorch_total_params = sum(p.numel() for p in model.parameters()) print(&#39;Total number of parameters: &#39;,pytorch_total_params) pytorch_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad) print(&#39;Trainable parameters: &#39;, pytorch_trainable_params) print(&#39;layers + activations&#39;,len(list(model.parameters()))) . . Total number of parameters: 98666 Trainable parameters: 98666 layers + activations 4 . The number of model parameters matches that of TF/Keras . class DeviceDataLoader(): &quot;&quot;&quot;Wrap a dataloader to move data to a device&quot;&quot;&quot; def __init__(self, dl, device): self.dl = dl self.device = device def __iter__(self): &quot;&quot;&quot;Yield a batch of data after moving it to device&quot;&quot;&quot; for b in self.dl: yield to_device(b, self.device) def __len__(self): &quot;&quot;&quot;Number of batches&quot;&quot;&quot; return len(self.dl) . train_loader = DeviceDataLoader(train_loader, device) val_loader = DeviceDataLoader(val_loader, device) test_loader= DeviceDataLoader(test_loader, device) . for xb, yb in val_loader: print(&#39;xb.device:&#39;, xb.device) xb = xb.view(xb.size(0), -1) break . xb.device: cuda:0 . history = [evaluate(model, val_loader)] history . [{&#39;val_acc&#39;: 0.09672564268112183, &#39;val_loss&#39;: 2.308856248855591}] . history = fit(20, 1e-3, model, train_loader, val_loader) history . Plot the losses and the accuracies to check if you&#39;re starting to hit the limits of how well your model can perform on this dataset. You can train some more if you can see the scope for further improvement. . plot_accuracies(history) . Finally, evaluate the model on the test dataset report its final performance. . evaluate(model, test_loader) . {&#39;val_acc&#39;: 0.33740234375, &#39;val_loss&#39;: 1.88686203956604} . Results . Accuracy Tensorflow/Keras : 0.3619999885559082 Pytorch: 0.33740234375 . The differences could be due to very little training and hence lack of convergence of the solution, the randomness of the weights intialisation and differences in the library implementations in TF and Pytorch and other stuff I am not aware of ;) . Concluding comments . This exercise was not to get an exact match of accuracy but to demonstrate the constructs between TF and Pytorch. . The Jovian course Pytorch Zero to GANS is a great introduction to Machine Learning. I am enjoying . Collaborating with others | Working through examples | Finishing assignments and submitting for approval | Blogging about my experiences | Staying enthusiastic about ML! | . Thanks and appreciation to: . Jeremy Howard and Hamel Hussain for the Fastpages framework in which this blog is written as a Jupyter notebook. | .",
            "url": "https://onpointai.github.io/onpointai/jovian/tensorflow/keras/pytorch/fastpages/jupyter/2020/06/12/tfkeras-pytorch-cifar10.html",
            "relUrl": "/jovian/tensorflow/keras/pytorch/fastpages/jupyter/2020/06/12/tfkeras-pytorch-cifar10.html",
            "date": " • Jun 12, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Loss Functions",
            "content": "About . A Loss Function is a function that calculates a single real number which indicates how far a prediction is from the actual. During the creation of a Machine Learning model the loss is minimised by using some type of algorithm also known as an Optimiser. The Optimiser optimises the result by reducing the loss. In general, the loss is calculated over a number of input examples (batch). . Tutorial Overiew . JASON BROWNLEE MACHINE LEARNING MASTERY . This tutorial is divided into three parts; they are: . Regression Loss Functions . Mean Squared Error Loss - default - distribution of target is gaussian - square of error means larger errors penalised more than smaller ones (Keras mse or mean_squared_error) . Mean Squared Logarithmic Error Loss . Mean Absolute Error Loss - distribution of target variable is mainly gaussian but may heave outliers (keras - mean_absolute_error) . Binary Classification Loss Functions - targets are either of two labels . **Binary Cross-Entropy (keras - binary_cross_entropy) . Hinge Loss - for use with SVM - binay classification where target values are in the set {-1,1} encourages examples to have the correct sign - assigning more errorwhen thee is a differene in sign between actual/predicted class values . Squared Hinge Loss - square of hinge loss - hass effect of smoothing the surfaceof the error function and making it easier to work with numerically . Multi-Class Classification Loss Functions - targets can belong to one of many labels or classes - predict probability of example beloging to each known class . Multi-Class Cross-Entropy Loss - use this first - calculate a score that summarizes the ave diff between actual and predicted probability distributions for all classes - keras -categorical_cross_entropy . Sparse Multiclass Cross-Entropy Loss - large nb of labels- eg words in a vocabulary may have tens or hundreds of thousands of categories, one for each label. No one-hot encoding keras - sparse_categorical_crossentropy . Kullback Leibler Divergence Loss KL divergence - measure of how one probability distribution differs from a baseline distribution KLdiv of 0 suggest distributions are identical calculates how much information is lost if the predicted target distributon is use to approximate the desired target probablity distribuion KLd more commonly used when using models that learn to approximate a more complex fn than simply multi-class ie autoencoding used for learning a dense feature representation under a model that must construct the original input . Regression loss functions . #&#39;/Users/dexterdsilva/Documents/Developer/MachineLearning/brownlee_mlm&#39; import os os.path.abspath(&#39;&#39;) . &#39;/Users/dexterdsilva/Documents/Developer/MachineLearning/brownlee_mlm&#39; . from sklearn.datasets import make_regression from sklearn.preprocessing import StandardScaler from keras.models import Sequential from keras.layers import Dense from keras.optimizers import SGD import matplotlib.pyplot as plt . Using TensorFlow backend. . import keras print(keras.__version__) import tensorflow as tf print(tf.__version__) . 2.3.1 2.1.0 . #generate regression dataset #20 X,y=make_regression(n_samples=1000, n_features=20,noise=0.1, random_state=1) . X[0] . array([ 0.58372668, 0.78593639, -0.17187155, 0.66928708, 1.67181016, 0.59831823, 1.49807611, 0.27925069, -0.31705821, -0.41961259, -0.21796143, 0.81186707, -0.79215259, 0.56621046, 0.97473625, -0.8223744 , 1.03007179, -0.67945508, -0.21540618, 1.03118947]) . print(y.shape) f&#39;{y[0]}&#39; print(type(y)) . (1000,) &lt;class &#39;numpy.ndarray&#39;&gt; . X=StandardScaler().fit_transform(X) . X[0] . array([ 0.64516745, 0.76000873, -0.18010938, 0.65740427, 1.65197553, 0.56574009, 1.50368462, 0.30416606, -0.29634854, -0.37041198, -0.22745535, 0.72392625, -0.76421488, 0.55675061, 0.96630152, -0.82406123, 0.95038766, -0.76479647, -0.2088517 , 1.04702956]) . y=StandardScaler().fit_transform(y.reshape(len(y),1))[:,0] . n_train=500 trainX, testX = X[:n_train,:], X[n_train:,:] trainy, testy = y[:n_train], y[n_train:] . model= Sequential() model.add(Dense(25, input_dim=20,activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;)) model.add(Dense(1, activation=&#39;linear&#39;)) . opt=SGD(lr=0.01, momentum=0.9) . Mean Squared Error Loss . model.compile(loss=&#39;mse&#39;, optimizer = opt) . h=model.fit(trainX, trainy, validation_data=(testX,testy), epochs=100, verbose=0) . h.history.keys() . dict_keys([&#39;val_loss&#39;, &#39;loss&#39;]) . fig= plt.figure(figsize=(5,5)) plt.plot(h.history[&#39;loss&#39;],label=&#39;train_loss&#39;) plt.plot(h.history[&#39;val_loss&#39;], label=&#39;test_loss&#39;) plt.legend() plt.show() . Mean Squared Logarithmic Error Loss . model=Sequential() model.add(Dense(25, input_dim=20, activation =&#39;relu&#39;, kernel_initializer = &#39;he_uniform&#39;)) model.add(Dense(1, activation = &#39;linear&#39;)) opt=SGD(lr=0.1, momentum=0.9) model.compile(loss=&#39;mean_squared_logarithmic_error&#39;, optimizer=opt, metrics=[&#39;mse&#39;]) . print(trainX.shape,&#39; &#39;,trainy.shape,&#39; &#39;, testX.shape,&#39; &#39;, testy.shape) . (500, 20) (500,) (500, 20) (500,) . h = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=0) . # evaluate the model _,train_mse=model.evaluate(trainX, trainy, verbose=0) _,test_mse=model.evaluate(testX, testy, verbose=0) . print(&#39;Train: {:.2f} Test {:.2f}&#39;.format(train_mse, test_mse)) . Train: 0.31 Test 0.37 . h.history.keys() . dict_keys([&#39;val_loss&#39;, &#39;val_mse&#39;, &#39;loss&#39;, &#39;mse&#39;]) . fig=plt.figure(figsize=(10,10)) plt.subplot(211) plt.title(&#39;Loss&#39;) plt.plot(h.history[&#39;loss&#39;],label=&#39;Training Loss&#39;) plt.plot(h.history[&#39;val_loss&#39;],label = &#39;Test Loss&#39;) plt.legend() plt.subplot(212) plt.title(&#39;Mean Squared Error&#39;) plt.plot(h.history[&#39;mse&#39;], label=&#39;train&#39;) plt.plot(h.history[&#39;val_mse&#39;], label=&#39;test&#39;) plt.legend() plt.show() . Mean Absolute Error Loss . X,y=make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=1) . print(X.shape, y.shape,&#39; &#39;, type(y)) plt.scatter(X[:,1],y) . (1000, 20) (1000,) &lt;class &#39;numpy.ndarray&#39;&gt; . &lt;matplotlib.collections.PathCollection at 0x13e0af090&gt; . len(y) . 1000 . X=StandardScaler().fit_transform(X) y=StandardScaler().fit_transform(y.reshape(len(y),1)) . n_train=500 trainX, testX = X[:n_train,:],X[n_train:,:] trainy, testy = y[:n_train], y[n_train:] . model= Sequential() model.add(Dense(25,input_dim=20, activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;)) model.add(Dense(1, activation=&#39;linear&#39;)) opt=SGD(lr=0.01, momentum=0.9) model.compile(loss=&#39;mean_absolute_error&#39;, optimizer=opt,metrics=[&#39;mse&#39;]) . h=model.fit(trainX, trainy,validation_data=(testX, testy), epochs=100, verbose=1) . _,train_mse=model.evaluate(trainX, trainy, verbose=1) . 500/500 [==============================] - 0s 18us/step . _,test_mse=model.evaluate(testX, testy, verbose=1) . 500/500 [==============================] - 0s 19us/step . h.history.keys() . dict_keys([&#39;val_loss&#39;, &#39;val_mse&#39;, &#39;loss&#39;, &#39;mse&#39;]) . print(&#39;Train: {:.4f} Test:{:.4f}&#39;.format(train_mse, test_mse)) . Train: 0.0042 Test:0.0036 . fig=plt.figure(figsize=(10,10)) plt.subplot(121) plt.title(&#39;LOSS&#39;) plt.plot(h.history[&#39;loss&#39;], label=&#39;train&#39;) plt.plot(h.history[&#39;val_loss&#39;], label=&#39;test&#39;) plt.legend() plt.subplot(122) plt.title(&#39;MSE&#39;) plt.plot(h.history[&#39;mse&#39;],label=&#39;train&#39;) plt.plot(h.history[&#39;val_mse&#39;], label=&#39;test&#39;) plt.legend() plt.show() . Classification Loss Functions . from sklearn.datasets import make_circles from sklearn.preprocessing import StandardScaler from keras.models import Sequential from keras.layers import Dense from keras.optimizers import SGD from numpy import where import matplotlib.pyplot as plt %matplotlib inline . X,y = make_circles(n_samples=1000,noise=0.1, random_state=1) for i in range(2): samples_idx= where(y==i) plt.scatter(X[samples_idx,0], X[samples_idx,1], label=str(i)) plt.legend() plt.show() . print(X[:5]) print(y[:5]) . [[ 0.92787748 -0.04521731] [-0.54303182 -0.75444674] [ 0.9246533 -0.71492522] [-0.10217077 -0.89283523] [-1.01719242 0.24737775]] [1 1 0 0 0] . n_train=500 trainX,testX=X[:n_train,:],X[:n_train] trainy,testy = y[:n_train], y[:n_train] . print(trainX.shape ,&#39; &#39;, trainy.shape) . (500, 2) (500,) . Binary Cross Entropy . model=Sequential() model.add(Dense(50, input_dim=2, activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;)) model.add(Dense(1, activation=&#39;sigmoid&#39;)) opt=SGD(lr=0.01, momentum=0.9) model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=opt, metrics=[&#39;accuracy&#39;]) . h=model.fit(trainX, trainy, validation_data=(testX,testy), epochs=200,verbose=1) . #_,train_acc=model.evaluate(trainX,trainy, verbose=1) . 500/500 [==============================] - 0s 44us/step . _,test_acc=model.evaluate(testX, testy,verbose=1) . 500/500 [==============================] - 0s 25us/step . print(&#39;Train: {:.4f} Test:{:.4f}&#39;.format(train_acc, test_acc)) . Train: 0.8360 Test:0.8360 . h.history.keys() . dict_keys([&#39;val_loss&#39;, &#39;val_accuracy&#39;, &#39;loss&#39;, &#39;accuracy&#39;]) . fig=plt.figure(figsize=(8,4)) plt.subplot(121) plt.title(&quot;LOSS&quot;) plt.plot(h.history[&#39;loss&#39;], label=&#39;train&#39;) plt.plot(h.history[&#39;val_loss&#39;], label=&#39;test&#39;) plt.legend() plt.subplot(122) plt.title(&quot;ACCURACY&quot;) plt.plot(h.history[&#39;accuracy&#39;], label=&#39;train&#39;) plt.plot(h.history[&#39;val_accuracy&#39;], label=&#39;test&#39;) plt.legend() plt.show() . Hinge Loss . y[where(y==0)]= -1 . X,y = make_circles(n_samples=1000, noise=0.1, random_state=1) y[where(y==0)]= -1 . n_train=500 trainX,testX= X[:n_train,:],X[n_train:,:] trainy,testy=y[:n_train],y[n_train:] . model=Sequential() model.add(Dense(50,input_dim=2,activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;)) model.add(Dense(1, activation=&#39;tanh&#39;)) opt=SGD(lr=0.01, momentum=0.9) model.compile(loss=&#39;hinge&#39;, optimizer=opt,metrics=[&#39;accuracy&#39;]) . model.summary() . Model: &#34;sequential_14&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_24 (Dense) (None, 50) 150 _________________________________________________________________ dense_25 (Dense) (None, 1) 51 ================================================================= Total params: 201 Trainable params: 201 Non-trainable params: 0 _________________________________________________________________ . h=model.fit(trainX,trainy,validation_data=(testX,testy), epochs=200, verbose=1) . model.metrics_names . [&#39;loss&#39;, &#39;accuracy&#39;] . _,train_acc=model.evaluate(trainX,trainy, verbose=1) . 500/500 [==============================] - 0s 21us/step . _,test_acc=model.evaluate(testX,testy, verbose= 1) . 500/500 [==============================] - 0s 19us/step . print(&#39;Train: {:.4f} Test: {:.4f}&#39;.format(train_acc, test_acc)) . Train: 0.8380 Test: 0.8380 . h.history.keys() . dict_keys([&#39;val_loss&#39;, &#39;val_accuracy&#39;, &#39;loss&#39;, &#39;accuracy&#39;]) . fig =plt.figure(figsize=(10,5)) plt.subplot(1,2,1) plt.title(&#39;ACCURACY&#39;) plt.plot(h.history[&#39;accuracy&#39;], label=&#39;train&#39;) plt.plot(h.history[&#39;val_accuracy&#39;], label = &#39;test&#39;) plt.legend() plt.subplot(1,2,2) plt.title(&quot;LOSS&quot;) plt.plot(h.history[&#39;loss&#39;], label=&#39;train&#39;) plt.plot(h.history[&#39;val_loss&#39;], label=&#39;test&#39;) plt.legend() plt.show() . Squared Hinge Loss . X,y = make_circles(n_samples=1000, noise=0.1, random_state=1) y[where(y==0)]= -1 . n_train=500 trainX,testX = X[:n_train,:],X[n_train:,:] trainy,testy=y[:n_train],y[n_train:] . collapse-hide model = Sequential() model.add(Dense(50, input_dim=2, activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;)) model.add(Dense(1, activation=&#39;tanh&#39;)) opt=SGD(lr=0.01, momentum=0.9) model.compile(loss=&#39;squared_hinge&#39;, optimizer=opt, metrics=[&#39;accuracy&#39;]) h = model.fit(trainX,trainy,validation_data=(testX,testy), epochs=200, verbose=1) . print(model.metrics_names) res_train = model.evaluate(trainX,trainy) res_test = model.evaluate(testX, testy) . [&#39;loss&#39;, &#39;accuracy&#39;] 500/500 [==============================] - 0s 18us/step 500/500 [==============================] - 0s 18us/step . print(&#39;Traina cc:{:.4f} Test acc:{:.4f}&#39;.format(res_train[1], res_test[1])) . Traina cc:0.6820 Test acc:0.6660 . h.history.keys() . dict_keys([&#39;val_loss&#39;, &#39;val_accuracy&#39;, &#39;loss&#39;, &#39;accuracy&#39;]) . fig=plt.figure(figsize=(8,2)) plt.subplot(121) plt.title(&quot;LOSS&quot;) plt.plot(h.history[&#39;loss&#39;], label=&#39;train&#39;) plt.plot(h.history[&#39;val_loss&#39;], label=&#39;test&#39;) plt.legend() plt.subplot(122) plt.title(&quot;ACCURACY&quot;) plt.plot(h.history[&#39;accuracy&#39;], label=&#39;train&#39;) plt.plot(h.history[&#39;val_accuracy&#39;], label=&#39;test&#39;) plt.legend() plt.show() . Multi-class classification . Multi-class cross-entropy . from sklearn.datasets import make_blobs X,y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2) . print(X[:5], &#39; &#39;, y[:5]) . [[ 0.48719811 -0.43160548] [ -1.48958879 -3.47915742] [ -2.06250444 -7.73300419] [ -0.51369303 -10.31546366] [ 0.56240126 -2.18246169]] [2 2 2 0 1] . for i in range(3): samples_idx = where(y==i) plt.scatter(X[samples_idx,0], X[samples_idx,1], label=str(i)) plt.legend() plt.show() . from keras.utils import to_categorical X,y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2) y = to_categorical(y) #NO ONEHOT ENCODING FOR SPARSE n_train=500 trainX,testX = X[:n_train,:],X[n_train:,:] trainy,testy=y[:n_train],y[n_train:] . print(trainy.shape) print(y[:5]) . (500, 3) [[0. 0. 1.] [0. 0. 1.] [0. 0. 1.] [1. 0. 0.] [0. 1. 0.]] . model = Sequential() model.add(Dense(50, input_dim=2, activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;)) model.add(Dense(3, activation=&#39;softmax&#39;)) opt=SGD(lr=0.01, momentum=0.9) #model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=opt, metrics=[&#39;accuracy&#39;]) model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=opt, metrics=[&#39;accuracy&#39;], ) h = model.fit(trainX,trainy,validation_data=(testX,testy), epochs=200, verbose=1) . model.metrics_names . [&#39;loss&#39;, &#39;accuracy&#39;] . res_train = model.evaluate(trainX,trainy) res_test = model.evaluate(testX, testy) print(&#39;Train acc:{:.4f} Test acc:{:.4f}&#39;.format(res_train[1], res_test[1])) . 500/500 [==============================] - 0s 42us/step 500/500 [==============================] - 0s 33us/step Train acc:0.8320 Test acc:0.8260 . h.history.keys() . dict_keys([&#39;val_loss&#39;, &#39;val_accuracy&#39;, &#39;loss&#39;, &#39;accuracy&#39;]) . #collapse-hide fig=plt.figure(figsize=(8,2)) plt.subplot(121) plt.title(&quot;LOSS&quot;) plt.plot(h.history[&#39;loss&#39;], label=&#39;train&#39;) plt.plot(h.history[&#39;val_loss&#39;], label=&#39;test&#39;) plt.legend() plt.subplot(122) plt.title(&quot;ACCURACY&quot;) plt.plot(h.history[&#39;accuracy&#39;], label=&#39;train&#39;) plt.plot(h.history[&#39;val_accuracy&#39;], label=&#39;test&#39;) plt.legend() plt.show() . . Sparse multi-class cross-entropy . from keras.utils import to_categorical X,y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2) y = to_categorical(y) NO ONEHOT ENCODING FOR SPARSE n_train=500 trainX,testX = X[:n_train,:],X[n_train:,:] trainy,testy=y[:n_train],y[n_train:] print(trainy.shape) print(y[:5]) . (500,) [2 2 2 0 1] . model = Sequential() model.add(Dense(50, input_dim=2, activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;)) model.add(Dense(3, activation=&#39;softmax&#39;)) opt=SGD(lr=0.01, momentum=0.9) #model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=opt, metrics=[&#39;accuracy&#39;]) model.compile(loss=&#39;sparse_categorical_crossentropy&#39;, optimizer=opt, metrics=[&#39;accuracy&#39;], ) h = model.fit(trainX,trainy,validation_data=(testX,testy), epochs=200, verbose=1) #res_train = model.evaluate(trainX,trainy) #res_test = model.evaluate(testX, testy) #print(&#39;Train acc:{:.4f} Test acc:{:.4f}&#39;.format(res_train[1], res_test[1])) . fig=plt.figure(figsize=(8,2)) plt.subplot(121) plt.title(&quot;LOSS&quot;) plt.plot(h.history[&#39;loss&#39;], label=&#39;train&#39;) plt.plot(h.history[&#39;val_loss&#39;], label=&#39;test&#39;) plt.legend() plt.subplot(122) plt.title(&quot;ACCURACY&quot;) plt.plot(h.history[&#39;accuracy&#39;], label=&#39;train&#39;) plt.plot(h.history[&#39;val_accuracy&#39;], label=&#39;test&#39;) plt.legend() plt.show() . Kullback Leibler Divergence . Measure of how one probablity distribution differs form another KL Div = 0 suggest dist are identical autoenoder used for learning dense featue representation under a model that must reconstruct the original input . #collapse-hide from sklearn.datasets import make_blobs from keras.layers import Dense from keras.models import Sequential from keras.optimizers import SGD from keras.utils import to_categorical import matplotlib.pyplot as plt . . X,y = make_blobs(n_samples=1000,centers=3,n_features=2, cluster_std=2, random_state=2) . y[:5] . array([2, 2, 2, 0, 1]) . y = to_categorical(y) . y[:5] . array([[0., 0., 1.], [0., 0., 1.], [0., 0., 1.], [1., 0., 0.], [0., 1., 0.]], dtype=float32) . n_train=500 trainX,testX = X[:n_train,:],X[n_train:,:] trainy, testy = y[n_train:],y[:n_train] . #collapse-hide model= Sequential() model.add(Dense(50, input_dim=2, activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;)) model.add(Dense(3, activation=&#39;softmax&#39;)) opt=SGD(lr=0.01, momentum=0.9) model.compile(loss=&#39;kullback_leibler_divergence&#39;, optimizer=opt, metrics=[&#39;accuracy&#39;]) . . h = model.fit(trainX ,trainy, validation_data=(testX, testy), epochs =100, verbose=1) . model.evaluate(trainX,trainy,verbose=1) . 500/500 [==============================] - 0s 49us/step . [1.0587191171646118, 0.41600000858306885] . model.metrics_names . [&#39;loss&#39;, &#39;accuracy&#39;] . h.history.keys() . dict_keys([&#39;val_loss&#39;, &#39;val_accuracy&#39;, &#39;loss&#39;, &#39;accuracy&#39;]) . fig=plt.figure(figsize=(8,2)) plt.subplot(121) plt.title(&quot;LOSS&quot;) plt.plot(h.history[&#39;loss&#39;], label=&#39;train&#39;) plt.plot(h.history[&#39;val_loss&#39;], label=&#39;test&#39;) plt.legend() plt.subplot(122) plt.title(&quot;ACCURACY&quot;) plt.plot(h.history[&#39;accuracy&#39;], label=&#39;train&#39;) plt.plot(h.history[&#39;val_accuracy&#39;], label=&#39;test&#39;) plt.legend() plt.show() . FIN .",
            "url": "https://onpointai.github.io/onpointai/ai/ml/jupyter/2020/06/05/lossfunctions.html",
            "relUrl": "/ai/ml/jupyter/2020/06/05/lossfunctions.html",
            "date": " • Jun 5, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Sports Video Classification",
            "content": "Overview . The simplest way to classify the type of video is by examining individual frames of the video ie treat individual frames as images, classify the images and then do some sort of averaging or smoothing over a few frames to predict the current display. . Once we understand what goes on here we can explore the other methods which take up more setup and compute. . The main package here is OpenCV, a library aimed at real-time computer vision tasks. . The dataset used was a collection of images curated using Google image search. . ├── Sports-Type-Classifier │ ├── data │ │ ├── badminton [938 entries] │ │ ├── baseball [746 entries] │ │ ├── basketball [495 entries] │ │ ├── boxing [705 entries] │ │ ├── chess [481 entries] │ │ ├── cricket [715 entries] │ │ ├── fencing [635 entries] │ │ ├── football [799 entries] │ │ ├── formula1 [687 entries] │ │ ├── gymnastics [719 entries] │ │ ├── hockey [572 entries] │ │ ├── ice_hockey [715 entries] │ │ ├── kabaddi [454 entries] │ │ ├── motogp [679 entries] │ │ ├── shooting [536 entries] │ │ ├── swimming [689 entries] │ │ ├── table_tennis [713 entries] │ │ ├── tennis [718 entries] │ │ ├── volleyball [713 entries] │ │ ├── weight_lifting [577 entries] │ │ ├── wrestling [611 entries] │ │ ├── wwe [671 entries] . Setup . The repo contains the data, Colab Jupyter notebooks and trained weights for different training regimes. . Results . . . . . . . .",
            "url": "https://onpointai.github.io/onpointai/ai/ml/video%20classification/2020/05/21/videoclassification.html",
            "relUrl": "/ai/ml/video%20classification/2020/05/21/videoclassification.html",
            "date": " • May 21, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Multi-label Image Classification",
            "content": "Overview . This is a tutorial from Analytics Vidhya . The dataset of images contain more than two categories ie it is not a simple either/or . Each image in the dataset can contain only one category . Example: A dataset containing images such as dog, cat, rabbit, parrot Each image contains only dog, cat, parrot rabbit . . The above is know as multi-label image classification. . Question: Can we predict the genre of a movie by looking at the movie poster? And ofcourse a movie can belong to more than one genre. . The key is in the output layer - use a sigmoid activation instead of softmax. With Softmax as the probablity of one increases the probability of the other classses decrease (becuase the sum must equal 1). With Sigmoid however the probabilities are independent of each other. So with sigmoid the architecture will internally create N models where N is the number of classes. Cool huh?! . Setup . For details of the model and data see repo . Note: No attempt has been made to finetune the architecture and reduce the amount of overfitting and hence get a better training/validation loss. . Results . . . .",
            "url": "https://onpointai.github.io/onpointai/ai/ml/multi-label%20image%20classification/2020/05/19/multilabelimageclass.html",
            "relUrl": "/ai/ml/multi-label%20image%20classification/2020/05/19/multilabelimageclass.html",
            "date": " • May 19, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Style Transfer using Neural Networks",
            "content": "Overview . This method renders the contents of a Original image in the style of a Reference image. For example in an image of a cityscape the contents can be considered as the hard edges of the buildings. The Reference image can contain lots of swirly patters and colours which will be know as the style of the image. The loss function is defined in parameter space as the difference between the content and style of the images as laid out below: . Loss = distance((style(reference_image) - style(generated_image)) + (distance(content(original_image) - content(generated_image)) . As a workflow exercise I attempted to render the image of an F1 car in the style of Picasso! I used images of recent Racing Point and Renault F1 cars. . Setup . The notebook, models and data are contained here . I trained it on Google Colab using both Tensorflow and Pytorch (separately ofcourse!) The trained model is implemented using a webapp. The user is asked to select an image and the analysis is displayed. . . Results . . Loss = distance((style(reference_image) - style(generated_image)) + (distance(content(original_image) - content(generated_image)) original_image = a picture of an F1 car reference_image = a style image such as Picasso . . .",
            "url": "https://onpointai.github.io/onpointai/ai/ml/style%20transfer/2020/05/18/neuralstyletransfer.html",
            "relUrl": "/ai/ml/style%20transfer/2020/05/18/neuralstyletransfer.html",
            "date": " • May 18, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Predict F1 Car Constructor from Image",
            "content": "Overview . This is an exercise based on Formula 1 cars and is aimed at predicting which team a car belongs to by analysing an image. The image can be from any angle. This is an end-to-end example ir from gathering the data, training a model and deploying the trained model using a webapp on a local server. . Setup . The training setup, data are in this repo . This is a good example of a complete workflow . collecting data using google web search (local) | cleaning the data (removing duplicate images and other rubbish) (local) | porting data to Google Colab - When i was doing this I did not have my Github a/c organised properly Otherwise I would have done git init and ported the local repo to github From Google Colab it is easy to clone the Github repo | Once the data is in repo start a new jupyter notebook and select a GPU for training. | Download the trained model to the local dir | Modify the webapp to point to the trained model and do the predictions | . Note: I only used about 75 images per class (10 classes) to cut down on the training time. . I used Fastai’s recommended Starlette web api and with a bit of playing around with the css and html file got something suitable. . This is only meant for demo purposes and to motivate me to carry on with the ret of the course. . Results . . . Suggested Improvements: . Add more training data | Clean training data | Overfit and then play around with hyperparameters | Give webapp better UI | . . .",
            "url": "https://onpointai.github.io/onpointai/ai/ml/image%20classification/2020/05/18/f1carspredictor.html",
            "relUrl": "/ai/ml/image%20classification/2020/05/18/f1carspredictor.html",
            "date": " • May 18, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Stochastic Gradient Descent",
            "content": "Overview . ML is basically this - you make a prediction, see how far that prediction is from the truth, fine-tune your prediction and keep going until the difference between between the prediction and the actual reaches an acceptable level. If we imagine the loss function plotted as a U curve then we are trying to reach the bottom of the curve as quickly as possible ie minimise the loss. From our starting point, a guess, we then take a small step in the direction of lower loss. The small step is known as the learning rate and the direction of lower loss is worked out from the slope of the curve. . Minimising the loss . Below is a regression example. The pink dots are the initial set of data. To this we have to find a general approximation that will satisfy any new points. Our initial guess is the black line. . We then go through the fllowing sequence: Loss = New Value - Actual Value Find slope of the loss function Move down the loss curve by a small amount (the Learning Rate) Find the new loss . . Pytorch implementation . y is the actual y_hat is the prediction (based on a set of weights a) loss is the mean squared error between y_hat and y def mse(y_hat,y): return((y_hat-y)**2).mean() def update(): y_hat = x@a loss=mse(y_hat,y) loss.backward() with torch.no_grad(): a.sub_(lr * a.grad) a.grad.zero_() . References . Fast.ai | Machine Learning Mastery | D :bowtie: — .",
            "url": "https://onpointai.github.io/onpointai/ai/ml%20gradient%20descent/2020/05/17/sgd.html",
            "relUrl": "/ai/ml%20gradient%20descent/2020/05/17/sgd.html",
            "date": " • May 17, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "An Overview of AI/ML",
            "content": "The contents of this page should be treated as a set of flashcards with each giving some insight into the definition, structure and scope of AI tools in everyday use. . Note: Reinforcement Learning (think Apha Go from Deep Dream/Google) has no practical applications at the moment for me and will therefore not be discussed. . . . . . . . . . . . . It has been shown that the winner is not necessarily the smartest or the one with the best computer. Instead it is the person who can develop their ideas quickly. . . .",
            "url": "https://onpointai.github.io/onpointai/ai/ml/visuals/2020/05/15/overview.html",
            "relUrl": "/ai/ml/visuals/2020/05/15/overview.html",
            "date": " • May 15, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Reference Material",
            "content": "This is a list of links to articles, blogposts, videos, tutorials that I have found very useful on my ML journey. It serves as a useful reference point and is ever-growing. . Setup . Tensorflow or Pytorch? . Google Colab . I love articles, tutorials, videos by the following: . Adrian Rosebrock Pyimagesearch. Andrej Karpathy blog. Chris Olah blog. Andrew Ng Coursera. Francois Chollet Book. Jeremey Howard Fast.ai. Rachel Thomas Fast.ai. Chris Albon Great flashcards - Buy them!. Aakash Nain Jovian. Hannah Fry [Makes number fun!]http://www.hannahfry.co.uk(). Jason Brownlee Tutorials. . Powerful Quotes . F Chollet: “You don’t need to know everything. You don’t really need a formal background in this or that – though it helps, you don’t even need a PhD. You do, however, need to be constantly learning, be curious, read books. Don’t be “too busy” to learn, or otherwise proud of your ignorance.” “Honestly, the question is not, and has never been, “ can ML replace radiologists/etc” (which won’t happen in the foreseeable future). The question is, how can radiology/etc utilise ML to improve outcomes, decrease the cost of car, and broaden accessibility.” . | Geoff Hinton: “Read enough sp you start developing intuitions and then trust your intuitions and go for it!.” . | Andrew Ng: “Deep Learning is a superpower. With it you can make a computer see, synthesize novel art, translate languages, render a medical diagnosis, or build pieces of a car that can drive itself. If that isn’t a superpower, I don’t know what is.” . | . . . Ignore stuff below. . . You can include alert boxes …and… . . You can include info boxes Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Tables . | Tensorflow | Pytorch | |-|-| | Keras | Fastai | — .",
            "url": "https://onpointai.github.io/onpointai/markdown/2020/05/14/referencematerial.html",
            "relUrl": "/markdown/2020/05/14/referencematerial.html",
            "date": " • May 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "My name is Dexter D’Silva . I am an Aeronautical Engineer having worked at: Airbus Wing Shape Team (High Speed Aerodynamics). EADS Innovation Works. Racing Point Formula 1 team (Aero Design processes). . I was always interested in writing macros, developing software on a one-off basis and saw myself writing advanced macros for CATIA automation initially in the field of wing shaping. . In 2017 I came across this video by Andrew Ng and since then I have been hooked on AI/Machine Learning and want to learn as much as I can about it with a view to applying my own spin on implementing flavours of it in the work that I do. . I am pretty good at connecting the dots of technology in the field of aero design where I work with CAD and CFD. I am always working on tutorials to build intuition about AI and explore it’s feasibility in my daily work, where my domain knowledge will help me to enhance my value to my customer/employer. . The other area of interest is exploring the use of AI to analyse the huge amount of data generated by CFD, wind tunnel testing and on-track or flight testing and building tools to gain easy access to knowledge, to decipher, disseminate and democratise within the organisation. . Here is my CV . Online courses with certificates . Coursera/Stanford | Deep Learning - AI for Everyone | Zero to Deep Learning | Deep Learning in Python | Supervised Learning - Scikit Learn | NLP - Python | Statistical Thinking in Python | Unsupervised Learning with Python | Intermediate Python for Data Science | Introduction Python for Data Science | Pandas Foundation | . Other Online Courses . Fast.ai | . Inspired by Fast.ai . . :cowboy_hat_face: . . .",
          "url": "https://onpointai.github.io/onpointai/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://onpointai.github.io/onpointai/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}